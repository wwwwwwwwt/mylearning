<!--
 * @Author: zzzzztw
 * @Date: 2023-03-21 15:51:12
 * @LastEditors: Do not edit
 * @LastEditTime: 2023-03-23 16:47:42
 * @FilePath: /cpptest/Redislearn/06主从库实现数据一致.md
-->
# 主从库如何实现数据一致？
1. 上两篇文章分别写了AOF日志文件和RDB快照，当redis发生宕机，分别可以通过回放AOF日志和重新读入RDB文件方式恢复数据，从而尽量避免少丢失数据，提升可靠性
2. 上述两种方法可以做到尽量少丢失数据，宕机可以进行恢复，但仍会出现宕机不提供服务的情况，针对这种情况，redis的做法时提供副本冗余量，将一份数据同时保存到多个实例上。

## redis提供了主从库模式，以保证数据副本一样，主从库之间采用了读写分离。
* 读操作：主库和从库都可以接受这个操作
* 写操作：只有主库可以执行写操作，然后主操作将写操作后的内容同步给从库

<center>

![](./img/06(1).png)

</center>

如果不采用主从库读写分离，那么可以对任一个库进行写操作这涉及到更多的加锁和同步问题，是巨大的开销。

## 主从库间第一次同步与规定
1. 当我们启动多个redis实例时，他们互相之间可以通过```replicaof```命令形成主库和从库的关系
* 比如我们由两个实例：ip 172.16.19.3和172.16.19.5, 我们在实例2上可以执行以下命令，此时实例2就成为了实例1的从库，并从实例1开始复制数据
```
replicaof 172.16.19.3 6379
```

2. 主从库之间进行数据第一次同步的三个阶段
* 1. 建立连接，确定同步位置
* 2. 主库收到同步数据的信号，开启一个bgsave线程生成RDB文件，此时新发来的操作消息由replication buffer记录下来，将发送RDB快照给从库，从库接收前先初始化，把自己清空
* 3. 主库将这段时间写入的增量数据通过replication buffer缓冲区（也有大小限制，超过大小限制将把这个client踢掉）发送给从库
<center>

![](./img/06(2).png)

</center>

1. 当频繁有从库加入时，主库就需要频繁制作rdb快照，占用系统资源，此时可以建立主-从-从的结构，将从库加到从库下面，分级进行rdb复制和传输

## 主从库网络断了怎么办？
1. 网络断了的时候，主从库会使用增量复制继续同步
2. 主从库断连后，主库会把断连期间收到的写操作命令分别写入replication buffer和repl_backlog_buffer
3. 从库连接上来后，向主库发从自己从处于从节点位置，开始读入自己掉线期间丢失的数据


## replication buffer 和 rep_backlog_buffer 的区别
* replication buffer 对于一主多从来说是相互独立，即redis会为每一个redis client创建一个独立的replication buffer，通过该buffer传输数据，
* repl_backlog_buffer 用于判断主从数据差异，是多个从库共用一个
* （每个从库有自己的slave_repl_offset记录当前复制主库数据的进度）用于断开重连时候使用此缓冲区恢复，每一个redis client都会有一个这个offset，该offset除了在断开重连后会通过psync将自己的offset传递给master.当发现这个偏移量已经被主库master offset覆盖时，这个从库只能进行一次全量复制了。没被覆盖就可以跟据偏移量进行增量数据复制（写入主从偏移量之间的命令操作）。可以通过调整repl_backlog_buffer环形缓冲区大小来避免被覆盖的情况。
* 主从还维护了一个心跳机制，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次，命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量告知master(实时更新主库repl_backlog_buffer上这个从库在环形缓冲区上的位置)，repl_backlog_buffer通过该offset进行移动。但由于是环形缓冲区，写速度大与读速度会导致一定数据还没读就被新的写上了，导致数据丢失。